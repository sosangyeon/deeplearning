Abstract
포인트 클라우드에서의 객체 감지는 자율주행과 같은 많은 로봇 응용 분야에서 중요한 측면이다. 
최근 문헌에서는 두 가지 유형의 인코더를 제안한다.
고정 인코더는 빠르지만 정확도가 떨어지는 경향이 있는 반면, 데이터에서 학습된 인코더는 더 정확하지만 속도가 느리다. 
(fixed encoder : 데이터로부터 학습되지 않은 사전 정의된 방법으로 입력 데이터를 인코딩하는 알고리즘이나 기법)
이 작업에서는 pointnets을 사용하여 수직 기둥으로 구성된 포인트 클라우드의 표현을 학습하는 새로운 인코더인 pointpillars를 제안한다. 
라이다만을 사용했음에도 불구하고 최첨단 성능을 달성한다.
이 감지 성능은 62Hz에서 실행되는 동안 달성되며, 이는 2-4배 향상된 런타임이다. 

1. Introduction
이를 달성하기 위해 자율 주행 차량은 여러 센서에 의존한다. 
전통적인 라이다 기반 로보틱스 시스템에서는, 먼저 포인트 클라우드에서 배경을 제거하고 객체를 감지한 후, 감지된 객체들을 클러스터링하고, 마지막으로 이 객체들을 분류하여 무엇인지를 식별하는 과정을 거친다.
1) 포인트 클라우드는 희소 표현이고 이미지는 조밀하며 2) 포인트 클라우드는 3D이고 이미지는 2D이다. 
결과적으로, 포인트 클라우드에서의 객체 감지는 표준 이미지 컨볼루션에 적합하지 않다.

초기 작업은 3D convolution 또는 포인트 클라우드를 이미지에 투영하는 기법에 초점을 맞추었다.
최근의 방법은 BEV에서 
