Abstract
LiDAR 기반 3D 물체감지는 자율 주행의 장거리 인식 작업에서 지배적인 작업이 되고 있다.
3D 객체 감지기는 일반적으로 네트워크 백본과 예측 헤드에 조밀한 특징 맵을 구축한다.
그러나 조밀한 기능 맵의 계산 및 공간 비용은 인식 범위에 대해 2차이므로 장거리 설정까지 확장하기 어렵다.
효율적인 장거리 LiDAR 기반 물체 감지를 가능하게 하기 위해 완전히 희소 3D 물체 감지기를 구축했다.
FSD의 계산 및 공간 비용은 포인트 수에 대략 선형이며 인식 범위와 무관하다.
FSD는 일반 희소 복셀 인코더와 새로운 희소 인스턴스 인식 모듈을 기반으로 한다.

SIR은 먼저 포인트를 인스턴스로 그룹화한 다음 인스턴스별 특징 추출 및 예측을 적용한다.
이러한 방식으로 SIR은 모든 센터 기반 또는 앵커 기반 감지기에 대한 완전 희소 아키텍처 설계를 방해하는 센터 기능 누락 문제를 
해결한다.
또한 SIR은 포인트를 인스턴스로 그룹화하여 이전 포인트 기반 방법에서 시간이 많이 걸리는 neighbor 쿼리를 방지한다.

1. Introduction
현재의 3D LiDAR 기반 물체 감지기는 일반적으로 추가 특징 추출 및 예측을 위해 희소 특징을 조밀한 기능 맵을 사용하는 감지기의 이름을 dense detectors로 지정한다.
고밀도 검출기는 인식 범위가 상대적으로 짧은 벤치마크에서 잘 작동한다.
그러나 밀집된 감지기를 장거리 설정으로 확장하는 것은 비현실적이다.

비어 있는 영역은 본질적으로 불필요하다.
내재된 희소성을 감안할 때, 효율적인 장거리 검출을 위한 필수 솔루션은 밀집된 특징 맵을 제거하고 네트워크 아키텍처를 완전히 희소 상태로 만드는 것이다.
그러나 조밀한 기능 맵을 제거하는 것은 현재 설계에서 중요한 역할을 하기 때문에 간단하지 않다.
일반적으로 채택되는 희소 복셀 인코더는 효율성을 위해 비어 있지 않은 복셀의 특징만 추출한다.
따라서 조밀한 기능 맵이 없으면 개체 중심은 일반적으로 비어 있으며, 특히 큰 개체의 경우 특히 그렇다.
-> CFM
복셀 또는 기둥 기반 감지기는 중심 기능이 전체 물체를 가장 잘 표현하기 때문에 중심 기반 또는 앵커 기반 할당을 채택한다.
그러나 CFM은 중앙 복셀의 표현력을 크게 약화시키며 초대형 차량과 같은 일부 극단적인 경우에는 중앙 기능을 비우게 만들기도 한다.
이러한 어려움을 감안할 때, 희소 복셀 인코더 이후 BEV에서 희소 복셀을 조밀한 특징 맵으로 변환해야 한다.
그런 다음 조밀한 피처 맵에 컨볼루션을 적용하여 피처를 인스턴스 센터로 확산시킴으로서 CFM 문제를 해결하며, 이를 피처 확산이라고 한다.

figure1
빈 인스턴스 센터는 여러 컨볼루션 후에 점유된 복셀에서 확산된 기능으로 채워진다.

조밀한 feature map을 적절하게 제거하기 위해 자연적으로 완전히 희박하기 때문에 순수 점 기반 감지기를 조사한다.
그러나 자율 주행 시나리오에서 포인트 기반 방법의 사용을 제한하는 두 가지 단점이 있다.
1) inefficiency
시간이 많이 걸리는 이웃 쿼리는 대규모 포인트 클라우드에 적용하는 데 오랜 어려움이 있다는 것이다.
2) coarse represent
계산 오버헤드를 줄이기 위해 포인트 기반 방법은 전체 장면을 고정된 포인트 수로  공격적인 다운샘플링은 불가피한 정보 손실과 전경 물체의 불충분한 회상으로 이어진다.

이 논문에서는 sparse voxel encoder와 point-based instance predictor의 장점을 모두 활용하는 fsd를 제안한다.
중앙 영역이 비어 있을 수 있기 때문에 감지기는 인스턴스의 비어 있지 않은 다른 부분에서 상자를 예측해야 한다.
그러나 개별 부품에서 전체 상자를 예측하면 회귀 목표값에 큰 분산이 발생하여 결과에 잡음이 많고 일관성이 없게 된다.
이를 통해 먼저 포인트를 인스턴스로 그룹화한 다음, 인스턴스 수준 기능을 추가홀 추출하고 인스턴스 기능에서 단일 경계 상자를 예측한다.
이 원칙을 구현하기 위해 FSD는 먼저 희소 복셀 인코더를 사용하여 복셀 기능을 추출한 다음 votenet과 같이 이러한 기능을 기반으로 개체 센터에 투표한다.
그런 다음 IPG 모듈은 연결된 구성 요소 레이블 지정을 통해 투표된 센터를 인스턴스로 그룹화한다.
그룹화 후 포인트 기반 SIR 모듈은 인스턴스 피처를 추출하고 전체 바운딩 박스를 예측한다.
점 기반 모듈인 SIR에는 몇 가지 원하는 속성이 있다.
1) 이전의 포인트 기반 모듈과 달리 SIR은 인스턴스를 그룹으로 취급하고 추가 그룹화를 위해 시간이 많이 걸리는 이웃 쿼리를 적용하지 않는다.
2) 동적 복셀화와 유사하게 SIR은 텐서 조작을 위해 동적 브로드캐스트/풀링을 활용하여 포인트 샘플링 또는 패딩을 방지한다.
3) SIR은 전체 인스턴스를 다루기 때문에 인스턴스의 물리적 크기에 관계없이 충분한 수용 필드를 구축한다.

2. related work
voxel-based dense detectors
선구적인 연구 결과인 voxelnet은 복셀 특징 추출을 위해 조밀 컨볼루션을 사용한다.
경쟁력 있는 성능을 달성하기는 하지만 3D 복셀 표현에 조밀한 컨볼루션을 적용하는 것은 비효율적이다.
PIXOR 및 PointPillars는 BEV기능 맵에서 2D 조밀 컨볼루션을 채택하여 효율성을 크게 개선했다.
이러한 검출기를 dense detector라고 부르는 이유는 희소 포인트 클라우드를 dense feature map으로 변환하기 때문이다.

voxel-based semi-dense detector
dense detectors와 달리 semi-dense detectors는 sparse feature와 dense feature를 모두 통합한다.
희소 컨볼루션을 채택하여 3D 공간에서 희소 복셀 특징을 추출한 다음 BEV에서 조밀한 특징 맵으로 변환하여 수용 필드를 확대하고 2D 감지 헤드와 통합한다.
second 스타일의 semi-dense detector를 기반으로 하는 많은 분석법은 세분화된 특징 추출 및 제안서 미세 조정을 위해 두 번째 단계를 연결한다.
semi-dense detector는 centor feature missing 문제에 직면하게 될 것이기 때문에 fully sparse detector로 쉽게 들어 올리기 어렵다는 점은 주목할 만하다.

point-based sparse detectors
pointrcnn은 순수 점 기반 검출기를 구축하기 위한 선구적인 작업이다.
3DSSD는 특징 전파 계층과 미세 조정 모듈을 제거함으로써 점 기반 방법을 가속화한다.
votenet은 먼저 센터 투표를 만든 다음 투표 센터에서 제안서를 생성하여 정밀도를 높인다.
많은 방법이 포인트 기반 방법을 가속화하려고 시도했지만 시간이 많이 걸리는 이웃 쿼리는 여전히 대규모 포인트 클라우드에서 감당할 수 없다.
-> 복셀 기반 검출기가 우세

3 Methodology
3.1 overall architecture
개체들의 그룹 동기에 따라, 우리는 완전 희소 검출기를 구축하기 위한 네 가지 단계를 거쳐야 한다.
1) 먼저 희소 복셀 인코더를 사용하여 복셀 특징을 추출하고 객체 중심에 투표한다.
2) 인스턴스 포인트 그룹화 : 투표 결과에 따라 전경 포인트를 인스턴스로 그룹화한다.
3) 그룹화 결과가 주어지면 SIR 모듈은 인스턴스/포인트 기능을 추출하고 제안서를 생성한다.
4) 제안은 포인트 그룹화를 수정하고 다른 SIR모듈을 통해 제안을 구체화하는데 사용된다.

3.2 instance point grouping
classication and voting
먼저 희소 복셀 인코더를 사용하여 포인트 클라우드에서 복셀 기능을 추출한다.
FSD가 특정 희소 복셀 인코더에 국한되지는 않지만 입증된 효과로 인해 SST에서 희소 어텐션 블록을 사용한다.
그런 다음 복셀 기능과 포인트에서 해당 복셀 중심으로의 오프셋을 연결하여 포인트 피처를 구축한다.
이러한 포인트 피처는 전경 분류 및 중앙 투표를 위해 두 개의 헤드로 전달된다.
투표는 votenet과 유사하며, 모델은 전경점에서 해당 객체까지의 오프셋을 예측한다.
L1 loss 및 Focal Loss는 투표 손실 및 분류 손실로 채택된다.

connected components labeling
점을 인스턴스로 그룹화하기 위해 예측된 모든 중심을 그래프의 꼭짓점으로 간주한다.
두 꼭짓점은 거리가 특정 임계값보다 작은 경우 연결된다.
그러면 이 그래프의 연결된 구성 요소를 인스턴스로 볼 수 있으며, 이 연결된 구성 요소에 투표된 모든 포인트는 그룹 ID를 공유한다.
votenet의 ball 쿼리와 달리 ccl 기반 그룹화는 단편화된 인스턴스를 크게 방지한다.
정교하게 설계된 인스턴스 그룹화 방법이 많이 있지만, 간단한 CCL을 선택한다.

3.3 Sparse Instance Recognition
3.3.1 Preliminaries: Dynamic Broadcast/Pooling
N개의 점들이 M개의 그룹에 속해 있다.
예를 들어, N개의 점이 있을 때 이 점들을 M개의 그룹으로 나눌 수 있다.
각 점이 속한 그룹을 나타내는 배열을 I라고 정의하고, 그 크기는 [N]이다.
즉, 이 배열은 N개의 점이 각각 어떤 그룹에 속하는지를 표시한다.
각 점은 F라는 배열에 자신의 특징값을 가지며, 이 배열의 크기는 [N,C]이다.
여기서 C는 각 점의 특징 차원수이다. 즉, 한 점이 여러 개의 특징을 가질 수 있는데, 그 차원을 의미한다.

dynamic pooling
dynamic pooling은 각 그룹에 속한 점들의 특징 값을 하나의 그룹 특징으로 집계하는 과정을 말한다.
예를 들어, 한 그룹에 속한 점들이 많을 때, 그 모든 점들의 특징 값을 하나의 대표 값으로 압축하는 방법이 풀링이다.
그룹 i에 속한 점들의 특징 값을 F(i)라고 하고, 그걸 집계한 값이 g_i가 된다.
즉, g_i=p(F(i))가 된다.
여기서 p는 대칭적은 풀링 함수로, 보통 average, max같은 함수
이렇게 각 그룹에 대한 특징 값을 계산한 후, 모든 그룹에 대해 G라는 배열을 얻을 수 있는데, 이 배열의 크기는 [M,C]이다.
즉, M개의 그룹에 대해 각 그룹의 특징 값을 [C]차원으로 갖게 되는 것이다.

dynamic broadcast
풀링의 반대되는 개념
브로드캐스트는 하나의 값을 다시 원래 개별 점들에 분배하는 과정이다.
g_i를 다시 그룹 i에 속한 점들에게 할당하는 것을 말한다.
즉, G[I]는 원래 점들의 개수인 [N,C] 크기를 갖게 된다.
이때 G[I]는 I배열을 이용해 각 점이 속한 그룹의 특징 값을 해당 점들에게 분배하는 방식이다.
즉, G[I]는 각 점이 속한 그룹의 특징을 다시 개별 점들로 브로드캐스트하는 것이다.

동적 브로드캐스트/풀링의 전제 조건은 각 포인트가 그룹에 고유하게 속해야 한다는 것
-> 그룹은 서로 겹치지 않아야 한다. 

3.3.2 Formulation of Sparse Instance Recognition
1) group center
2) pair-wise feature
3) group feature aggrregation

group center
그룹 중심은 해당 그룹을 대표하는 점이다.

Pair-wise Feature
Pair-wise Feature은 각 점에 대한 특징을 추출하는데 사용되는 입력을 정의한다.
SIR에선는 두가지 Pair-wise Feature를 사용한다.
1) 그룹 중심과 각 점 간의 상대적 좌표 : 그룹 중심과 개별 점 사이의 거리 및 방향을 나타낸다.
2) 그룹과 이웃 점 간의 특징 결합 : 각 점과 해당 그룹의 특징을 결합하는 방식
수식으로 나타내면, CAT(F, G[I])
F라는 점들의 특징과 G[I]라는 그룹 특징을 결합하는 것을 의미 
여기서 CAT는 채널 결합(Channel Concatenation)을 의미

Group Feature Aggregation
그룹 내에서 이웃한 점들의 특징을 모아서 하나의 그룹 특징을 만드는 과정
SIR은 이를 위해 동적 풀링을 사용

SIR 모듈의 구체적인 레이어 구조
SIR 모듈은 VFE의 구조를 기반으로 한 두 개의 레이어로 구성된다.
이를 통해 SIR 모듈을 구성하고 각 레이어에서 특징을 업데이트한다.

첫 번째 연산은 pair-wise feature를 계산하는 과정이다.
좌표 x에서 그룹 중심을 빼서 상대적 좌표를 계산한 후, 점별 특징 값과 결합한다.
이 결합된 값을 완전 연결 계층, 정규화, 활성화 함수를 통해 처리 -> F'_l

두번째 연산은 집계된 특징을 기반으로 다시 점들의 특징을 업데이트하는 과정
첫번째 연산에서 나온 결과를 다시 풀링 함수를 사용하여 집계하고, 다시 점들의 특징과 결합한다.

3.3.3 sparse prediction
sparse prediction은 희소한 데이터에 대해 예측을 수행하는 방법이다.
SIR을 통해 모든 인스턴스의 특징을 동적으로 병렬 처리하여 예측을 만든다.
sparse prediction : 한 그룹에 대해 단일 예측만 생성한다.

dense prediction과의 차이점
dense prediction은 각 점마다 예측을 만들어내는 방식이다. 
반면에, sparse prediction은 그룹 전체에 대해 하나의 예측을 만든다.
즉, 그룹을 기반으로 개별 점마다 예측을 만드는 것이 아니라 그룹 단위로 예측을 수행하는 것이 핵심이다.

sparse prediction의 이점
라벨 할당 문제 회피: Dense Prediction에서는 라벨 할당이 문제가 될 수 있다. 특히, 중심에 특징이 없는 경우, 앵커(anchor)나 앵커 포인트를 빈 보셀에 할당해야 하는 어려움이 있다.
중복되지 않는 그룹: Sparse Prediction에서는 그룹들이 서로 겹치지 않기 때문에 이런 문제가 없다. 각 그룹은 고유하며, 그룹의 중심에 기반하여 단일 예측을 생성한다.
균형 문제 해결: 완전히 희소한 아키텍처에서는 불균형 문제가 발생할 수 있다. 예를 들어, 짧은 거리의 객체는 많은 점을 포함하고, 먼 거리의 객체는 상대적으로 적은 점을 포함할 수 있다. 
이를 해결하기 위해 일부 방법들은 수작업으로 만든 정규화 인자를 사용하지만, SIR에서는 그룹별로 하나의 예측만 생성하기 때문에 이러한 불균형을 피할 수 있다.

SIR의 예측 방식
각 SIR 레이어에서 집계된 그룹 특징은 해당 그룹의 특징을 나타낸다.
즉, 이전에 풀링된 결과로, 그룹 전체에 대한 대표 특징을 나타낸다.
각 레이어에서 계산된 특징을 모아서, 전체 그룹에 대한 특징을 하나로 만든다.
최종적으로 이 결합된 그룹 특징을 사용하여 bounding box와 class label을 예측한다.

3.4 Group Correction
SIR은 물체를 포함할 수 있는 바운딩 박스를 예측한다.
이 바운딩 박스 내의 모든 점은 이전에 속한 그룹에 관계없이 수정된 그룹에 속하게 된다.
이 과정에서 SIR2라는 새로운 SIR 모듈이 사용된다. SIR2는 SIR에서 제안한 그룹에 대해 추가로 예측을 수행한다.

SIR2의 역할
SIR2는 바운딩 박스의 proposal과 실제 경계 상자 간의 잔차를 예측한다.
이는 많은 2단계 검출기에서 사용하는 방식이다.
포인트 특징 추가 : SIR2에서 바운딩 박스의 크기와 위치를 인식하기 위해, 각 점에서 바운딩 박스 경계까지의 오프셋을
추가적인 포인트 특징으로 사용한다. 







