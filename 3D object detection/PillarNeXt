Abstract
희소하고 구조화되지 않은 원시 포인트 클라우드를 처리하기 위해 LiDAR 기반 3D 객체 감지 연구는 주로 세분화된 기하학적 모델링을 위한
전용 로컬 포인트 어그리게이터를 설계하는데 중점을 둔다.
계산 자원 할당의 관점에서 로컬 포인트 집계를 다시 살펴본다.
가장 단순한 기둥 기반 모델이 정확도와 대기 시간을 모두 고려할 때 놀라울 정도로 잘 수행된다는 것을 발견했다.
또한 수용 영역 확장과 같은 2D 물체 감지의 성공으로 인한 최소한의 적응이 성능을 크게 향상시킨다는 것을 보여준다.

1. Introduction
LiDAR 포인트 클라우드의 3D 물체 감지는 인식, 예측, 계획에 이르기까지 후속 온보드 모듈에 중요한 정보를 제공하기 때문에
자율 주행 시스템의 필수 작업이다.
이 분야에서는 포인트 클라우드에 대처하도록 특별히 설계된 정교한 네트워크를 개발하기 위한 광범위한 연구 노력이 있다.
포인트 클라우드의 희박하고 불규칙한 특성으로 인해 대부분의 기존 작업은 포인트 클라우드를 필라, 복셀, range view와 같은
일반 그리도로 변환하는 그리드 기반 방법을 채택하여 정규 연산자를 적용할 수 있다.
그러나 그리드 기반 방법은 필연적으로 정보 손실을 유발하여 특히 작은 물체의 경우 열등한 결과를 초래한다는 것이 일반적인 믿음이다.
최근 연구에서는 점과 거드 기반 표현을 결합하기 위해 세분화된 기하학적 모델링을 위한 하이브리드 설계를 제안한다.

대부분의 기존 작품은 여전히 현대화된 디자인이 부족한 second 또는 pointpillars의 독창적인 아키텍처 위에 구축되어 있다.
한편, 밀접하게 관련된 분야에서는 이미지에서 2D 물체 감지가 놀라운 발전을 이루었는데, 
2D 물체 감지의 연구 초점은 3D 물체 감지와 크게 다르다.
앞서 언급한 관찰에 비추어 볼 때, 우리는 LiDAR 포인트 클라우드에서 3D 물체 감지를 위해 무엇을 중점적으로 고려해야 하는지 재고한다.
특히, 3D 객체 감지 모델을 설계할 때 발생하는 두 가지 근본적인 문제인 로컬 포인트 어그리게이터와 네트워크 아키텍처를 다시 살펴본다.

1) 계산 비용 관점
세분화된 집계기는 일반적으로 대략적인 집계보다 더 광범위한 컴퓨팅 리소스를 필요로 한다.
예를 들어, 복셀 기반 어그리게이터는 3D 컨볼루션을 사용하는데, 이는 2D 컨볼루션에 비해 느리고 계산 비용을 훨씬 많이 든다.

이로 인해 계산 비용이나 네트워크 용량을 효과적으로 할당하는 방법에 대한 질문이 제기된다.
세밀한 구조에 리소스를 사용해야 하나?
거친 그리드에 할당해야 하나?
-> no!
비슷한 계산 비용과 향상된 전략으로 훈련할 때 더 단순한 기둥 기반 모델은 보행자와 같은 작은 물체에 대해서도 복셀 기반 모델보다 우수하거나
동등한 성능을 달성할 수 있으며 다중 보기 융합 기반 모델보다 훨씬 우수한 성능을 발휘할 수 있다.
이로 인해 실제 성능 향상과 세분화된 로컬 3D 구조의 필요성에 대해 도전한다.

2) 네트워크 아키텍처 관점
2D 객체 감지의 성공에서 최소한의 조정을 수행하는 네트워크 성능이 우수하다는 것을 보여준다.
예를 들어, 한 가지 중요한 발견은 수용 영역을 적절하게 확장하면 상당한 개선이 이루어진다는 것이다.
다중 스케일 기능 융합에 의존하는 이전 작업과 달리 최종 단계에서 충분한 수용 영역을 가진 단일 스케일이 더 나은 성능을 얻는다.
이러한 유망한 결과는 3D 물체 감지가 2D 영역에서 잘 개발된 성공적인 방법을 계승할 수 있음을 시사한다.
위 연구 결과를 바탕으로 pillarnext라고 하는 기둥 기반 네트워크를 제안한다.

1) 계산 비용 관점에서 서로 다른 로컬 포인트 집계 장치를 비교하는 첫 번째 작업이다.
pillar가 voxel에 비해 유사한 3D mAP와 더 나은 BEV mAP를 달성할 수 있으며 3D 및 BEV mAP 모두에서 다중 보기 융합을 크게 
능가한다는 것을 보여줌으로써 일반적인 믿음에 도전한다.

2) 2D 물체 감지의 성공에 영감을 받아 수용 영역을 확장하는 것이 3D 물체 감지에 중요하다는 것을 알게 되었다.
최소한의 적응으로 당사의 검출기는 포인트 클라우드를 위한 정교한 설계로 기존 방법을 능가한다.

2. Related Work
LiDAR based 3D Object Detection
기존 방법은 대략적으로 포인트, 그리드 및 하이브리드 기반 표현으로 분류할 수 있으며, 이는 로컬 포인트 집계기에 따라 가능하다.
포인트 기반 방법, pointrcnn은 rcnn을 사용하여 제안서를 생성한다. 
다음 rol 풀링으로 각 제안을 구체화한다.
그러나 이러한 방법으로 인접 포인트 집계를 수행하는 것은 비용이 매우 많이 들기 때문에 자율 주행에서 대규모 포인트 클라우드를 처리하는 것은
현실적으로 불가능하다.

반면에 그리드 기반 방법은 포인트 클라우드를 2D 또는 3D 컨볼루션을 적용할 수 있는 구조화된 그리도로 불연속화한다.
voxelnet에서 3D 공간을 복셀로 분할하고 각 복셀 내부의 포인트 피처를 집계한 다음 밀도가 높은 3D 컨볼루션이 컨텍스트 모델링에 사용된다.
second는 희소 3D 컨볼루션을 도입하여 효율설을 향상시킨다.
pointpillar는 포인트 클라우드를 수직 열로 구성하고 2D 컨볼루션을 채택한다.
또 다른 그리드 기반 표현은 2D 컨볼루션에 의해 효율적으로 처리될 수 있는 range view이다.
다중 뷰 융합 방법은 기둥/복셀 및 범위 뷰 기반 표현을 모두 활용한다.
효율성에도 불구하고 그리드 기반 방법은 세밀한 정보 손실을 유발한다는 것은 직관적으로 알 수 있다.
-> 포인트 피처를 그리드 표현에 통합하기 위해 하이브리드 방법이 제안된다.
이 작업에서는 대신 기본 네트워크 아키텍처와 관련 훈련에 초점을 맞추고, 세분화된 로컬 기하학적 모델링이 과대평가되었음을 보여준다.

feature fusion and receptive field
멀티 스케일 기능 융합은 계층적 기능을 하향식 방식으로 집계하는 기능 피라미드 네트워크에서 시작된다.
높은 수준의 의미론과 낮은 수준의 공간 단서를 결합하기 위해 2D 객체 감지에 널리 사용된다.
PANet은 상향식 융합도 중요하다고 지적한다. 
둘 다 기능 맵을 직접 합산하여 융합을 수행한다.
BiFPN은 서로 다른 스케일의 특징이 불평등하게 기여한다는 것을 보여주며, 중요도를 조정하기 위해 
학습 가능한 가중치를 채택한다.
feature fusion의 상호 연관된 요소로서, 수용 영역은 2D 검출 및 세분화에서도 광범위하게 연구되고 검증된다.
ASPP를 제안하여 여러 유효 수용 필드를 가진 기능을 샘플링한다.
TridentNet은 서로 다른 팽창 계수를 가진 세 가지 컨볼루션을 적용하여 수용 필드 범위를 객체 스케일 범위와 일치시킨다.
이와 유사한 전략이 YOLOF에도 도입되었는데, 이는 수용장을 확대하는 동시에 원래 수용장을 유지하기 위해 확장된
잔차 블록을 사용한다.
특징 융합 및 수용 필드에 관한 이러한 기술은 2D 영역에서 광범위하게 채택되었지만 3D 영역에서는 거의 논의되지 않았다.
이 분야에 있는 대부분의 기존 네트워크는 여전히 voxelnet의 아키텍처를 따르거나 수정한다.
이 작업에서는 최신 디자인을 3D 물체에 통합하는 것을 목표로 한다.

model scaling
이 측면은 분류, 감지 및 세분화 작업을 포함한 이미지 영역에서 잘 연구되었다.
깊이, 너비 및 해상도를 공동으로 높이면 정확도가 향상되는 것으로 관찰되었다.
EfficientNet은 분류를 위한 복합 스케일링 규칙을 제안하며, 이 규칙은 나중에 객체 감지로 확장된다.
모델 용량이 모델 성능에 영향을 미친다는 것이 일반적인 합의이다.
따라서 건전한 결론을 얻기 위해 다른 방법의 비교는 모델 용량을 고려해야 한다.
second의 깊이, 너비 및 해상도를 조정하여 각 구성 요소의 중요도를 찾는다.

3. Network Architecture Overview
런타임 효율성과 2D 물체 감지에 대한 근접성 때문에 그리드 기반 모델에 중점을 둔다.
일반적으로 그리드 기반 네트워크는 
1) 원시 포인트 클라우드를 구조화된 기능 맵으로 변환하기 위한 그리드 인코더
2) 일반 기능 추출을 위한 백본
3) 다중 스케일 기능 융합을 위한 넥
4) 작업별 출력을 위한 감지 헤드로 구성된다.
기존 네트워크는 이러한 모든 구성 요소를 함께 결합하는 경우가 많다.

3.1. Grid Encoder
그리드 인코더는 포인트 클라우드를 구조화된 그리드로 불연속화한 다음 각 그리드 내의 포인트를 예비 기능 표현으로
변환하고 집계하는데 사용된다.
1) pillar : 기둥 기반 그리드 인코더는 세로 열에 점을 정렬하고 다층 퍼셉트론을 적용한 다음 최대 풀링을 적용하여 
가상 이미지로 표현되는 필라 특징을 추출한다.
2) voxel : 기둥과 유사하게, 복셀 기반 그리드 인코더는 복셀의 포인트를 구성하고 해당 기능을 얻는다.
기둥과 비교할 때 복셀 인코더는 높이 치수를 따라 세부 사항을 보존한다.
3) Multi-View Fusion : MVF 기반 그리드 인코더는 필러/복셀 및 범위 보기 기반 표현을 결합한다.

3.2. Backbone and Neck
백본은 그리드 인코더에서 추출한 예비 기능을 기반으로 추가 기능 추상화를 수행한다.
공정한 비교를 위해 resnet-18을 백본으로 사용하는데, 이는 이전 작업에서 일반적으로 사용되었기 때문이다.
특히, pillar 또는 MVF 기반 인코더를 사용하여 백본의 희소 2D 컨볼루션을 사용하고 복셀 기반 엔코더를 사용하여 
백본의 희소 3D 컨볼루션을 사용한다.
그런 다음 넥을 활용하여 수용 영역을 확장하고 다중 스케일 컨텍스트를 융합하기 위해 백본에서 기능을 집계할 수 있다.
그러나 효과적인 넥을 설계하는 방법은 이미지와 비교하여 포인트 클라우드에서 물체 감지를 위해 잘 탐구되지 않았다.

3.3 Detection Head
second 및 pointpillar의 선구적인 작업에서 앵커 기반 감지 헤드는 입력 기능 맵의 각 위치에서 축에 정렬된 앵커를 미리 정의하는데 사용된다.
대신 centerpoint는 중심점으로 각 개체를 나타내고 각 중심 위치에서 경계 상자의 회귀가 실현되는 중심성 히트맵을 예측한다.
모든 네트워크에 있는 센터 근거한 탐지 head를 채택한다.
기능 업샘플링, 다중 그룹화 및 IoU 분기와 같은 헤드의 간단한 수정 세트를 보여 주어 성능을 눈에 띄게 향상시킨다.

4. Experiments
4.1. Experimental Setup
waymo open dataset과 nuscenes의 두 가지 대규모 자율 주행 벤치마크에 대한 실험을 수행한다.
WOD는 훈련을 위한 789개의 시퀀스와 검증을 위한 202개의 시퀀스로 구성되며, 10Hz에서 5개의 LiDAR로 캡처된다.
공식 프로토콜에 따라 평균 정밀도 및 평균 정밀도 가중 헤딩을 평가 지표로 사용한다.
성능을 L1과 L2의 두 가지 난이도로 나누며, 전자는 최소 5점으로 물체를 평가하고 후자는 모든 물체를 최소 1점으로 평가한다.
차량, 보행자 및 자전거 이용자에 대한 IoU 임계값을 0.7, 0.5, 0.5로 설정한다.

nuScenes에는 각각 약 20초 분량의 1000개의 장면이 포함되어 있으며, 20Hz에서 32빔 LiDAR로 캡처된다.
주석은 키프레임에서 2Hz로 사용할 수 있다.

WOD 
12epoch동안 각 모델을 훈련하고 달리 명시되지 않는 한 3프레임을 입력을 사용한다.
추론을 위해 차량, 보행자 및 자전거 운전자에 대해 0.7, 0.2 및 0.25의 NMS 임계값을 사용한다.

4.3 comparison on waymo
일반적인 관행으로 단일 프레임과 다중 프레임을 별도로 사용하는 방법을 나열한다.
완전성을 위해 장기 시간 모델링을 사용하는 방법과도 비교한다.
우리의 모델은 희미한 복사 및 붙여넣기 데이터 증강을 통해 36개의 epoch 동안 훈련되었다.
단일 프레임 모델은 이미 많은 다중 프레임 방법을 능가한다.
미세 조정을 위해 전체 시퀀스를 사용하는 오프보드 방식 3DAL과 비교할 때 3프레임 모델은 더 나은 성능을 달성한다.















